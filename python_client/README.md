# ğŸ“¦KubetorchğŸ”¥

**A Python interface for running ML workloads on Kubernetes**

Kubetorch enables you to run any Python code on Kubernetes at any scale by specifying required resources, distribution, and scaling directly in code. It provides caching and hot redeployment for 1-2 second iteration cycles, handles hardware faults and preemptions programmatically, and orchestrates complex, heterogeneous workloads with built-in observability and fault tolerance.

## What Kubetorch Enables

- **100x faster iteration** from 10+ minutes to 1-3 seconds for complex ML applications like RL and distributed training
- **50%+ compute cost savings** through intelligent resource allocation, bin-packing, and dynamic scaling
- **95% fewer production faults** with built-in fault handling with programmatic error recovery and resource adjustment

---

[Apache 2.0 License](https://github.com/run-house/runhouse/blob/main/LICENSE)

**ğŸƒâ€â™€ï¸ Built by [Runhouse](https://www.run.house) ğŸ **
