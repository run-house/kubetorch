{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7HhB8gzONko"
   },
   "source": [
    "# Compute: Clusters, Functions, Packages, & Envs\n",
    "\n",
    "Runhouse has several abstractions to provide a seamless flow of code and execution across local and remote compute. The abstractions are cloud provider-agnostic, and provide living, reusable services.\n",
    "\n",
    "The Cluster and Function APIs blur the line between program execution and deployment.\n",
    "\n",
    "The Env and Package APIs help to provide convenient dependency isolation and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9N3gmCDuBz7D"
   },
   "source": [
    "## Install Runhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvtcN7-IW0q1"
   },
   "outputs": [],
   "source": [
    "!pip install runhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sO6l-O17W2da",
    "outputId": "e5673b71-b3a0-4444-fcab-f382c9d3e1e7"
   },
   "outputs": [],
   "source": [
    "import runhouse as rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rlNI26B2yI"
   },
   "source": [
    "Optionally, to login to Runhouse to sync any secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCE3cuAvyRKd",
    "outputId": "a9fe3809-d790-4b15-dd20-dfb8977590e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO | 2023-05-18 12:22:00,336 | No auth token provided, so not using RNS API to save and load configs\n",
      "INFO | 2023-05-18 12:22:00,867 | NumExpr defaulting to 2 threads.\n",
      "\n",
      "            ____              __                             @ @ @\n",
      "           \u001b[35m/\u001b[0m __ \\__  ______  \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m\u001b[95m_\u001b[0m  ____  __  __________     \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m___\n",
      "          \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m ___/ _ \\   \u001b[35m/\u001b[0m    \u001b[35m/\u001b[0m\\____    @@\n",
      "         \u001b[35m/\u001b[0m _, _/ \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[1m(\u001b[0m__  \u001b[1m)\u001b[0m  __/  \u001b[35m/_/\u001b[0m\\_/\u001b[35m/____/\u001b[0m\\  @@@@\n",
      "        \u001b[35m/_/\u001b[0m |_|\\__,_/_/ \u001b[35m/_/_/\u001b[0m \u001b[35m/_/\u001b[0m\\____/\\__,_/____/\\___/   | || |||__|||   ||\n",
      "        \n",
      "\u001b[1;33mRetrieve your token üîë here to use üèÉ üè† Runhouse for secrets and artifact \u001b[0m\n",
      "\u001b[1;33mmanagement: \u001b[0m\u001b[4;94mhttps://run.house/account#\u001b[0m\u001b[4;94mtoken\u001b[0m\n",
      "Token: \n",
      "Download config from Runhouse to your local .rh folder? [y/N]: y\n",
      "Download secrets from Vault to your local Runhouse config? [y/N]: y\n",
      "Upload your local config to Runhouse? [y/N]: y\n",
      "Upload your enabled cloud provider secrets to Vault? [y/N]: y\n",
      "INFO | 2023-05-18 12:22:41,881 | Getting secrets from Vault.\n",
      "INFO | 2023-05-18 12:22:44,593 | Found credentials in shared credentials file: ~/.aws/credentials\n",
      "\u001b[2K\u001b[32m‚†¶\u001b[0m Updating AWS catalog: aws/vms.csv (every 7 hours)\n",
      "\u001b[2K\u001b[32m‚†π\u001b[0m Updating AWS catalog: aws/images.csv (every 7 hours)\n",
      "\u001b[1A\u001b[2KI 05-18 12:22:47 aws_catalog.py:119] \u001b[2mFetching availability zones mapping for AWS...\u001b[0m\n",
      "WARNING | 2023-05-18 12:22:55,953 | Received secrets ['gcp', 'lambda'] which Runhouse did not auto-detect as configured. For cloud providers, you may want to run `sky check` to double check that they're enabled and to see instructions on how to enable them.\n",
      "INFO | 2023-05-18 12:22:55,954 | Saved secrets from Vault to local config files\n",
      "INFO | 2023-05-18 12:22:56,169 | Found credentials in shared credentials file: ~/.aws/credentials\n",
      "Upload secrets for aws? [y/N]: y\n",
      "Upload secrets for sky? [y/N]: y\n",
      "Upload secrets for ssh? [y/N]: y\n",
      "Upload secrets for github? [y/N]: y\n",
      "INFO | 2023-05-18 12:23:06,954 | Uploaded secrets for to Vault for: ['aws', 'sky', 'ssh', 'github']\n",
      "INFO | 2023-05-18 12:23:06,955 | Successfully logged into Runhouse.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!runhouse login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFyFUIziPr_8"
   },
   "source": [
    "## Cluster\n",
    "\n",
    "Runhouse provides various APIs for interacting with remote clusters, such as terminating an on-demand cloud cluster or running remote CLI or Python commands from your local dev environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2uS7S0wVSGC"
   },
   "source": [
    "### Initialize your Cluster\n",
    "\n",
    "There are two types of supported cluster types:\n",
    "1. Bring-your-own (BYO) Cluster, one that you have access to through an IP address and SSH credentials.\n",
    "2. On-Demand/Auto Cluster one that is associated with your cloud account, and automatically spun up/down for you.\n",
    "\n",
    "Each cluster must be provided with a unique `name` identifier during construction. This `name` parameter is used for saving down or loading previous saved clusters, and also used for various CLI commands for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHdQYmqV0cjh"
   },
   "outputs": [],
   "source": [
    "# BYO cluster\n",
    "cluster = rh.cluster(  # using private key\n",
    "              name=\"cpu-cluster\",\n",
    "              ips=['<ip of the cluster>'],\n",
    "              ssh_creds={'ssh_user': '<user>', 'ssh_private_key':'<path_to_key>'},\n",
    "          )\n",
    "\n",
    "cluster = rh.cluster(  # using password\n",
    "              name=\"cpu-cluster\",\n",
    "              ips=['<ip of the cluster>'],\n",
    "              ssh_creds={'ssh_user': '<user>', 'password':'******'},\n",
    "          )\n",
    "\n",
    "# Using a Cloud provider\n",
    "cluster = rh.ondemand_cluster(\n",
    "              name=\"cpu-cluster\",\n",
    "              instance_type=\"CPU:8\",\n",
    "              provider=\"cheapest\",       # \"AWS\", \"GCP\", \"Azure\", \"Lambda\", or \"cheapest\" (default)\n",
    "              autostop_mins=60,          # Optional, defaults to default_autostop_mins; -1 suspends autostop\n",
    "          )\n",
    "# Launch the cluster, only supported for on-demand clusters\n",
    "cluster.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvKA9ms7YG8S"
   },
   "source": [
    "You can set default configs for future cluster constructions. These defaults are associated with either only your local environment (if you don't login to Runhouse), or can be reused across devices (if they are saved to your Runhouse account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzlhtsJ85Jq-",
    "outputId": "b5002963-a7f8-4203-b32c-57a97025e6e4"
   },
   "outputs": [],
   "source": [
    "rh.configs.set('use_spot', False)\n",
    "rh.configs.set('default_autostop', 30)\n",
    "\n",
    "rh.configs.upload_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShqXfg-N4bH5"
   },
   "source": [
    "### Useful Cluster APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NxHtqZ8Y4VT"
   },
   "source": [
    "To run CLI or Python commands on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzV9lm-RZFsu",
    "outputId": "58939594-2d81-4ec8-a6ed-3a327c16e01c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:35:44.910826 | Running command on cpu-cluster: pip install numpy && pip freeze | grep numpy\n",
      "Warning: Permanently added '34.205.23.213' (ED25519) to the list of known hosts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.25.2)\n",
      "numpy==1.25.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.25.2)\\nnumpy==1.25.2\\n',\n",
       "  \"Warning: Permanently added '34.205.23.213' (ED25519) to the list of known hosts.\\r\\n\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run(['pip install numpy && pip freeze | grep numpy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrUdY0UFyE4N",
    "outputId": "43a75332-3b0d-426f-eb0d-1abb00c786b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:35:50.911455 | Running command on cpu-cluster: python3 -c \"import numpy; print(numpy.__version__)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '1.25.2\\n', '')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run_python(['import numpy', 'print(numpy.__version__)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MPecZONYieM"
   },
   "source": [
    "To ssh into the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QkBHXuOX-HR"
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "cluster.ssh()\n",
    "\n",
    "# CLI\n",
    "!ssh cpu-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNgFqBWxYpg-"
   },
   "source": [
    "To tunnel a JupyterLab server into your local browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NK8L9truXMRf"
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "cluster.notebook()\n",
    "\n",
    "# CLI\n",
    "!runhouse notebook cpu-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G70D-DeD6Gq7"
   },
   "source": [
    "To open a port, if you want to run an application on the cluster that requires a port to be open, e.g. Tensorboard, Gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6wE0kA2EmGv"
   },
   "outputs": [],
   "source": [
    "cluster.ssh_tunnel(local_port=7860, remote_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbrJu_LkONNo"
   },
   "source": [
    "## Function\n",
    "\n",
    "Runhouse's Function API lets you define functions to be run on remote hardware (your cluster above!). Simply pass in a local (or a GitHub) function, the intended remote hardware, and any dependencies; Runhouse will handle the rest for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D913pflCPxh2"
   },
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkJdhRFYzQTt"
   },
   "source": [
    "Let's start with a simple local function `getpid`, which takes in an optional parameter `a` and returns the process ID plus `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vDpxfh3oPuA4"
   },
   "outputs": [],
   "source": [
    "# Local Function\n",
    "def getpid(a=0, b=0):\n",
    "    import os\n",
    "    return os.getpid() + a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gko4Qdsf0HJi"
   },
   "source": [
    "To construct a function that runs `getpid` on a remote cluster, we wrap it using `rh.function`, and specify `system=cluster`. There are two ways of doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FI6SVrsBdHD8",
    "outputId": "e45084e8-6f1c-4dd4-9885-3ff55f3de53f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:59:14.328987 | Writing out function function to /Users/caroline/Documents/runhouse/runhouse/docs/notebooks/basics/getpid_fn.py. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body).\n",
      "INFO | 2023-08-29 03:59:14.332706 | Setting up Function on cluster.\n",
      "INFO | 2023-08-29 03:59:14.807140 | Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "INFO | 2023-08-29 03:59:15.280859 | Authentication (publickey) successful!\n",
      "2023-08-28 23:59:15,284| ERROR   | Problem setting SSH Forwarder up: Couldn't open tunnel :50052 <> 127.0.0.1:50052 might be in use or destination not reachable\n",
      "ERROR | 2023-08-29 03:59:15.284394 | Problem setting SSH Forwarder up: Couldn't open tunnel :50052 <> 127.0.0.1:50052 might be in use or destination not reachable\n",
      "INFO | 2023-08-29 03:59:15.879253 | Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "INFO | 2023-08-29 03:59:16.386013 | Authentication (publickey) successful!\n",
      "2023-08-28 23:59:16,388| ERROR   | Problem setting SSH Forwarder up: Couldn't open tunnel :50053 <> 127.0.0.1:50052 might be in use or destination not reachable\n",
      "ERROR | 2023-08-29 03:59:16.388522 | Problem setting SSH Forwarder up: Couldn't open tunnel :50053 <> 127.0.0.1:50052 might be in use or destination not reachable\n",
      "INFO | 2023-08-29 03:59:16.928752 | Connected (version 2.0, client OpenSSH_8.2p1)\n",
      "INFO | 2023-08-29 03:59:17.409829 | Authentication (publickey) successful!\n",
      "INFO | 2023-08-29 03:59:17.534412 | Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO | 2023-08-29 03:59:18.002794 | Checking server cpu-cluster\n",
      "INFO | 2023-08-29 03:59:19.059074 | Server cpu-cluster is up.\n",
      "INFO | 2023-08-29 03:59:19.061851 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 03:59:20.822780 | Calling env_20230829_035913.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method install on module env_20230829_035913\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:59:22.728154 | Time to call env_20230829_035913.install: 1.91 seconds\n",
      "INFO | 2023-08-29 03:59:22.981633 | Function setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Remote Function\n",
    "getpid_remote = rh.function(fn=getpid).to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWHaw8bx0tQS"
   },
   "source": [
    "To run the function, simply call it just as you would a local function, and the function automatically runs on your specified hardware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoFbUjcYdTCW",
    "outputId": "6da0aeef-36b0-4936-b700-633c09292be4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:59:43.821391 | Calling getpid.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local function result: 7592\n",
      "base servlet: Calling method call on module getpid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 03:59:44.078775 | Time to call getpid.call: 0.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote function result: 1382396\n"
     ]
    }
   ],
   "source": [
    "print(f\"local function result: {getpid()}\")\n",
    "print(f\"remote function result: {getpid_remote()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcYGq1ojP26V"
   },
   "source": [
    "### Git Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1dgblrD08bp"
   },
   "source": [
    "A neat feature of Runhouse is the ability to take a function from a Github repo, and create a wrapper around that function to be run on remote. This saves you the effort of needing to clone or copy a function. To do so, simply pass in the function url into `rh.function`.\n",
    "\n",
    "We've implemented the same `getpid` function [here](https://github.com/run-house/runhouse/blob/main/docs/notebooks/sample_fn.py). Below, we demonstrate how we can directly use the GitHub link and function name to run this function on remote hardware, without needing to clone the repo ourselves or reimplement the function locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpZN_vPUP2bh",
    "outputId": "deccfc49-3cf4-4e84-ba74-7f81639f7680"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:00:01.870718 | Setting up Function on cluster.\n",
      "INFO | 2023-08-29 04:00:01.873021 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 04:00:03.145979 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 04:00:04.625905 | Calling env_20230829_035957.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method install on module env_20230829_035957\n",
      "Installing package: GitPackage: https://github.com/run-house/runhouse.git@main\n",
      "Pulling: git -C ./runhouse fetch https://github.com/run-house/runhouse.git\n",
      "Checking out revision: git checkout main\n",
      "Installing GitPackage: https://github.com/run-house/runhouse.git@main with method local.\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:00:08.100045 | Time to call env_20230829_035957.install: 3.47 seconds\n",
      "INFO | 2023-08-29 04:00:08.275688 | Function setup complete.\n"
     ]
    }
   ],
   "source": [
    "pid_git_remote = rh.function(\n",
    "    fn='https://github.com/run-house/runhouse/blob/main/docs/notebooks/sample_fn.py:getpid',\n",
    "    system=cluster,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwovMHbo2eGs",
    "outputId": "526cf0c5-a5c3-46b8-92b8-d9b899046699"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:00:12.015937 | Calling getpid.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method call on module getpid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:00:12.285294 | Time to call getpid.call: 0.27 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1382397"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_git_remote(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Call Types: `.remote` and `.run`\n",
    "\n",
    "You can use `fn.remote()` to have the function return a remote object, rather than the proper result. This is a convenient way to avoid passing large objects back and forth to your laptop, or to run longer execution in notebooks without locking up the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:42:17.026532 | Calling getpid.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method call on module getpid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:42:17.900012 | Time to call getpid.call: 0.87 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<runhouse.resources.blobs.blob.Blob at 0x154dab3d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpid_remote_obj = getpid_remote.remote()\n",
    "getpid_remote_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the data from the returned remote object, you can call `.fetch()` on the remote object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:42:18.626515 | Getting getpid_call_20230829_044209_708686\n",
      "INFO | 2023-08-29 04:42:18.780105 | Time to get getpid_call_20230829_044209_708686: 0.15 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1382396"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpid_remote_obj.fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a function async, use `fn.run()`, which returns a `run_key` that can be used to retrieve the results and logs at a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:42:20.182323 | Calling getpid.call\n",
      "INFO | 2023-08-29 04:42:20.318719 | Time to call getpid.call: 0.14 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'getpid_call_20230829_044212_868665'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpid_run_key = getpid_remote.run()\n",
    "getpid_run_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the result of the function run, you can call `cluster.get()` and pass in the `run_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:42:28.747188 | Getting getpid_call_20230829_044212_868665\n",
      "INFO | 2023-08-29 04:42:28.875886 | Time to get getpid_call_20230829_044212_868665: 0.13 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1382396"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.get(getpid_run_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFBxnx-2Knu4"
   },
   "source": [
    "### Function Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suFeG-GGcjRz"
   },
   "source": [
    "#### `stream_logs`\n",
    "\n",
    "To stream logs to local during the remote function call, pass in `stream_logs=True` to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vwVOSLMcd1n",
    "outputId": "e54ab648-bed6-4966-d632-f783d020fe7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:43:17.812658 | Calling getpid.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method call on module getpid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:43:18.107531 | Time to call getpid.call: 0.29 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1382396"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpid_remote(stream_logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJL0TXCnKvWr"
   },
   "source": [
    "Function logs are also automatically output onto a log file on cluster it is run on. You can refer to [Runhouse Logging Docs](https://www.run.house/docs/debugging_logging) for more information on accessing these logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n",
    "\n",
    "In addition to running basic functions remotely, Runhouse lets you define classes that live and are run remotely, through the Module API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting existing class to Runhouse Module\n",
    "\n",
    "If you have an existing non-Runhouse class that you would like to run remotely, you can do so as follows:\n",
    "\n",
    "```\n",
    "from package import Model\n",
    "\n",
    "RemoteModel = rh.module(cls=Model, system=cluster)\n",
    "remote_model = RemoteModel(model_id=\"bert-base-uncased\", device=\"cuda\")\n",
    "remote_model.predict(\"Hello world!\")  # Runs on cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own Runhouse Module\n",
    "\n",
    "To construct your own Runhouse Module class, simply subclass your class with `rh.Module`, instantiate it locally, and then send it over to your cluster.\n",
    "\n",
    "Note that because this class is constructed locally prior to being sent over to a remote cluster, if there is a computationally heavy operation such as loading a dataset or model that we only want to be done remotely, it should be wrapped in a function and run remotely. One way of doing so is through lazy initialization, as in the data property of the module below.\n",
    "\n",
    "```\n",
    "# pid_module.py\n",
    "\n",
    "import os\n",
    "import runhouse as rh\n",
    "\n",
    "class PIDModule(rh.Module):\n",
    "    def __init__(self, a: int=0):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        if not hasattr(self, '_data'):\n",
    "            self._data = load_dataset()\n",
    "        return self._data\n",
    "    \n",
    "    def getpid(self):\n",
    "        return os.getpid() + self.a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working in a notebook setting, we define the class in another file, `pid_module.py`, and load in the module for use below. For Python scripts, the class can be defined in the same file as the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-09-05 19:57:10.034443 | Calling PIDModule.getpid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method getpid on module PIDModule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-09-05 19:57:10.308916 | Time to call PIDModule.getpid: 0.27 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pid_module import PIDModule\n",
    "\n",
    "remote_module = PIDModule(a=5).to(cluster)\n",
    "remote_module.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D38sOsnPP5V_"
   },
   "source": [
    "## Env + Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9lns9sCZdt7"
   },
   "source": [
    "Our sample `getpid` function used only builtin Python dependencies, so we did not need to worry about the function environment.\n",
    "\n",
    "For more complex functions relying on external dependencies, Runhouse provides concepts for packages (individual dependencies/installations) and environments (group of packages or a conda env)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMOrsBjTP9lk"
   },
   "source": [
    "### Package Types\n",
    "\n",
    "Runhouse supports `pip`, `conda`, `reqs` and `git` packages, which can be constructed in the following ways.\n",
    "\n",
    "Often times, if using Packages in the context of environments (Envs), you don't need to construct them yourself, but can just pass in the corresponding string, and Runhouse internals will handle the conversion and installation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "S7TtI1aS5JSj"
   },
   "outputs": [],
   "source": [
    "pip_package = rh.Package.from_string(\"pip:numpy\")\n",
    "conda_package = rh.Package.from_string(\"conda:torch\")\n",
    "reqs_package = rh.Package.from_string(\"reqs:./\")\n",
    "git_package = rh.GitPackage(git_url='https://github.com/huggingface/diffusers.git',\n",
    "                            install_method='pip',\n",
    "                            revision='v0.11.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6eVhkQu6H6C"
   },
   "source": [
    "You can also send packages between local, remote, and file storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRBA-30UWknH"
   },
   "outputs": [],
   "source": [
    "local_package = rh.Package.from_string(\"local/path/to/folder\")\n",
    "\n",
    "package_on_s3 = local_package.to(system=\"s3\", path=\"/s3/path/to/folder\")\n",
    "package_on_cluster = local_package.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z65ZySQdQCaz"
   },
   "source": [
    "### Envs\n",
    "\n",
    "Envs, or environments, keep track of your package installs and corresponding versions. This allows for reproducible dev environments, and convenient dependency isolation and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaFnxpbZPOd2"
   },
   "source": [
    "#### Base Env\n",
    "\n",
    "The basic Env resource just consists of a list of Packages, or strings that represent the packages. You can additionally add any environment variables by providing a Dict or `.env` local file path, and also set the working directory to be synced over (defaults to base GitHub repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fsCsZiOJ8GUZ"
   },
   "outputs": [],
   "source": [
    "env = rh.env(reqs=[\"numpy\", reqs_package, git_package], env_vars={\"USER\": \"*****\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYaXVF2VZEnJ"
   },
   "source": [
    "When you send an environment object to a cluster, the environment is automatically set up (packages are installed) on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "5Mk8HKgFZe9M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:44:06.955053 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 04:44:08.250678 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 04:44:09.741572 | Calling env_20230829_044402._set_env_vars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method _set_env_vars on module env_20230829_044402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:44:10.028261 | Time to call env_20230829_044402._set_env_vars: 0.29 seconds\n",
      "INFO | 2023-08-29 04:44:10.029212 | Calling env_20230829_044402.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method install on module env_20230829_044402\n",
      "Installing package: Package: numpy\n",
      "Installing Package: numpy with method pip.\n",
      "Running: pip install numpy\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n",
      "Installing package: GitPackage: https://github.com/huggingface/diffusers.git@v0.11.1\n",
      "Pulling: git -C ./diffusers fetch https://github.com/huggingface/diffusers.git\n",
      "Checking out revision: git checkout v0.11.1\n",
      "Installing GitPackage: https://github.com/huggingface/diffusers.git@v0.11.1 with method pip.\n",
      "Running: pip install ./diffusers\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:44:19.111342 | Time to call env_20230829_044402.install: 9.08 seconds\n"
     ]
    }
   ],
   "source": [
    "env_on_cluster = env.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnZxyX9AQqw-"
   },
   "source": [
    "#### Conda Env\n",
    "\n",
    "The CondaEnv resource represents a Conda environment that can be used to set up reproducible Conda envs across clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2fwlQ0gRZhT"
   },
   "source": [
    "There are several ways to construct a Runhouse CondaEnv object using `rh.conda_env`, by passing in any of the following into the `conda_env` parameter:\n",
    "\n",
    "1. A yaml file corresponding to a conda environment config\n",
    "2. A dict corresponding to a conda environment config\n",
    "3. Name of an existing conda env on your local machine\n",
    "4. Leaving the argument empty. In this case, we'll construct a new Conda environment for you, using the list you pass into `reqs`.\n",
    "\n",
    "\n",
    "Beyond the conda config, you can also add any additional requirements you'd like to install in the environment by adding `reqs = List[packages]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lz2BZAH0QqXK"
   },
   "outputs": [],
   "source": [
    "# 1. config yaml file\n",
    "conda_env = rh.conda_env(conda_env=\"conda_env.yml\", reqs=[\"numpy\", \"diffusers\"], name=\"yaml_env\")\n",
    "# 2. config dict\n",
    "conda_dict = {\"name\": \"conda_env\", \"channels\": [\"conda-forge\"], \"dependencies\": [\"python=3.10.0\"]}\n",
    "conda_env = rh.env(conda_env=conda_dict, name=\"dict_env\")\n",
    "# 3. local conda env\n",
    "conda_env = rh.conda_env(conda_env=\"local_conda_env\", name=\"from_local_env\")\n",
    "# 4. empty, construct from reqs\n",
    "conda_env = rh.conda_env(reqs=[\"numpy\", \"diffusers\"], name=\"new_env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqHqsaGNTy14"
   },
   "source": [
    "As with the base env, we can set up a conda env on the cluster with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "CBYx4X3oVMod"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:48:21.600485 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 04:48:23.132095 | Calling new_env.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_env servlet: Calling method install on module new_env\n",
      "Env already installed, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 04:48:24.358608 | Time to call new_env.install: 1.23 seconds\n"
     ]
    }
   ],
   "source": [
    "conda_env_on_cluster = conda_env.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2F9cAkYVRGL"
   },
   "source": [
    "Previously in the cluster section, we mentioned several cluster APIs such as running CLI or Python commands. These all run on the base environment in the examples above, but now that we've defined a Conda env, let's demonstrate how we can accomplish this inside a Conda env on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "BEIQXjJKXYyx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 05:14:08.725396 | Running command on cpu-cluster: conda run -n new_env python3 -c \"import numpy; print(numpy.__version__)\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25.2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '1.25.2\\n\\n', '')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run Python command within the conda env\n",
    "cluster.run_python(['import numpy', 'print(numpy.__version__)'], env=conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install additional package on given env\n",
    "cluster.install_packages([\"pandas\"], env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc1W9n1S8HPy"
   },
   "source": [
    "## Putting it all together -- Cluster, Function/Module, Env\n",
    "\n",
    "Now that we understand how clusters, functions, and packages/environments work, we can go on to implement more complex functions that require external dependencies, and seamlessly run them on a remote cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "M-msQEA0WmAv"
   },
   "outputs": [],
   "source": [
    "def add_lists(list_a, list_b):\n",
    "  import numpy as np\n",
    "\n",
    "  return np.add(np.array(list_a), np.array(list_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAYAUXusa7Hk"
   },
   "source": [
    "Note that in the function defined, we include the import statement `import numpy as np` within the function. The import needs to be inside the function definition in notebook or interactive environments, but can be outside the function if being used in a Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sRHEbdJvbrR2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 05:20:27.959315 | Writing out function function to /Users/caroline/Documents/runhouse/runhouse/docs/notebooks/basics/add_lists_fn.py. Please make sure the function does not rely on any local variables, including imports (which should be moved inside the function body).\n",
      "INFO | 2023-08-29 05:20:27.962973 | Setting up Function on cluster.\n",
      "INFO | 2023-08-29 05:20:27.965670 | Copying package from file:///Users/caroline/Documents/runhouse/runhouse to: cpu-cluster\n",
      "INFO | 2023-08-29 05:20:29.406978 | Calling env_20230829_052021.install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method install on module env_20230829_052021\n",
      "Installing package: Package: numpy\n",
      "Installing Package: numpy with method pip.\n",
      "Running: pip install numpy\n",
      "Installing package: Package: runhouse\n",
      "Installing Package: runhouse with method reqs.\n",
      "reqs path: runhouse/requirements.txt\n",
      "pip installing requirements from runhouse/requirements.txt with: -r runhouse/requirements.txt\n",
      "Running: /opt/conda/bin/python3.10 -m pip install -r runhouse/requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 05:20:32.575986 | Time to call env_20230829_052021.install: 3.17 seconds\n",
      "INFO | 2023-08-29 05:20:32.774676 | Function setup complete.\n",
      "INFO | 2023-08-29 05:20:32.791597 | Calling add_lists.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base servlet: Calling method call on module add_lists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2023-08-29 05:20:33.086075 | Time to call add_lists.call: 0.29 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = rh.env(reqs=[\"numpy\"])\n",
    "add_lists_remote = rh.function(fn=add_lists).to(system=cluster, env=env)\n",
    "\n",
    "list_a = [1, 2, 3]\n",
    "list_b = [2, 3, 4]\n",
    "add_lists_remote(list_a, list_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agWXh0XoYnUw"
   },
   "source": [
    "Now that you understand the basics, feel free to play around with more complicated scenarios! You can also check out our additional API and example usage tutorials on our [docs site](https://www.run.house/docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Td4tq3e8NPS"
   },
   "source": [
    "## Cluster Termination\n",
    "\n",
    "To terminate the cluster, you can call `sky down cluster-name` in CLI or `cluster_obj.teardown()` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjrsEks-P7QE",
    "outputId": "8a1fdcd0-61d7-41db-a24f-cb86109497c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating 1 cluster: cpu-cluster. Proceed? [Y/n]: y\n",
      "\u001b[2K\u001b[1;36mTerminating 1 cluster\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[1A\u001b[2K\u001b[32mTerminating cluster cpu-cluster...done.\u001b[0m\n",
      "\u001b[2K\u001b[1;36mTerminating 1 cluster\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sky down cpu-cluster\n",
    "# or\n",
    "cluster.teardown()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
