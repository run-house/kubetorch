{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7HhB8gzONko"
   },
   "source": [
    "# Compute: Clusters, Functions, Packages, & Envs\n",
    "\n",
    "Runhouse has several abstractions to provide a seamless flow of code and execution across local and remote compute. The abstractions are cloud provider-agnostic, and provide living, reusable services.\n",
    "\n",
    "The Cluster, Function, and Module APIs blur the line between program execution and deployment.\n",
    "\n",
    "The Env and Package APIs help to provide convenient dependency isolation and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9N3gmCDuBz7D"
   },
   "source": [
    "## Install Runhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvtcN7-IW0q1"
   },
   "outputs": [],
   "source": [
    "!pip install runhouse[sky]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sO6l-O17W2da",
    "outputId": "e5673b71-b3a0-4444-fcab-f382c9d3e1e7"
   },
   "outputs": [],
   "source": [
    "import runhouse as rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rlNI26B2yI"
   },
   "source": [
    "Optionally, to login to Runhouse to sync any secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCE3cuAvyRKd",
    "outputId": "a9fe3809-d790-4b15-dd20-dfb8977590e8"
   },
   "outputs": [],
   "source": [
    "!runhouse login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFyFUIziPr_8"
   },
   "source": [
    "## Cluster\n",
    "\n",
    "A cluster is the most basic form of compute in Runhouse, largely representing a group of instances or VMs connected with Ray. They largely fall in two categories:\n",
    "1. Static clusters, which are accessed via IP addresses and SSH credentials.\n",
    "2. On-Demand clusters, which are automatically spun up and down for you with your local cloud account.\n",
    "\n",
    "Runhouse provides various APIs for interacting with remote clusters, such as terminating an on-demand cloud cluster or running remote CLI or Python commands from your local dev environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2uS7S0wVSGC"
   },
   "source": [
    "### Initialize your Cluster\n",
    "\n",
    "Each cluster must be provided with a unique `name` identifier during construction. This `name` parameter is used for saving down or loading previous saved clusters, and also used for various CLI commands for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHdQYmqV0cjh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Static cluster\n",
    "cluster = rh.cluster(  # using private key\n",
    "              name=\"cpu-cluster\",\n",
    "              ips=['<ip of the cluster>'],\n",
    "              ssh_creds={'ssh_user': '<user>', 'ssh_private_key':'<path_to_key>'},\n",
    "          )\n",
    "\n",
    "# On-demand cluster\n",
    "cluster = rh.ondemand_cluster(\n",
    "              name=\"cpu-cluster\",\n",
    "              instance_type=\"CPU:8\",\n",
    "              provider=\"cheapest\",       # \"AWS\", \"GCP\", \"Azure\", \"Lambda\", or \"cheapest\" (default)\n",
    "              autostop_mins=60,          # Optional, defaults to default_autostop_mins; -1 suspends autostop\n",
    "          )\n",
    "# Launch the cluster, only supported for on-demand clusters\n",
    "cluster.up_if_not()\n",
    "cluster.run([\"echo started!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShqXfg-N4bH5"
   },
   "source": [
    "### Useful Cluster APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NxHtqZ8Y4VT"
   },
   "source": [
    "To run CLI or Python commands on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzV9lm-RZFsu",
    "outputId": "58939594-2d81-4ec8-a6ed-3a327c16e01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.3)\n",
      "numpy==1.26.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  'Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.3)\\nnumpy==1.26.3\\n',\n",
       "  '')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run(['pip install numpy && pip freeze | grep numpy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrUdY0UFyE4N",
    "outputId": "43a75332-3b0d-426f-eb0d-1abb00c786b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, '1.26.3\\n', '')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run_python(['import numpy', 'print(numpy.__version__)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MPecZONYieM"
   },
   "source": [
    "To ssh into the cluster (which you probably want to do in an interactive shell rather than a notebook):\n",
    "\n",
    "```\n",
    "# Python\n",
    ">>> cluster.ssh()\n",
    "\n",
    "# CLI\n",
    "$ ssh cpu-cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G70D-DeD6Gq7"
   },
   "source": [
    "To open a port, if you want to run an application on the cluster that requires a port to be open, e.g. Tensorboard, Gradio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6wE0kA2EmGv"
   },
   "outputs": [],
   "source": [
    "cluster.ssh_tunnel(local_port=7860, remote_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbrJu_LkONNo"
   },
   "source": [
    "## Function\n",
    "\n",
    "Runhouse's Function API lets you define functions to be run on remote hardware (your cluster above!). Simply pass in a local (or a GitHub) function, the intended remote hardware, and any dependencies; Runhouse will handle the rest for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D913pflCPxh2"
   },
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkJdhRFYzQTt"
   },
   "source": [
    "Let's start with a simple local function `getpid`, which takes in an optional parameter `a` and returns the process ID plus `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vDpxfh3oPuA4"
   },
   "outputs": [],
   "source": [
    "# Local Function\n",
    "def getpid(a=0, b=0):\n",
    "    import os\n",
    "    return os.getpid() + a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gko4Qdsf0HJi"
   },
   "source": [
    "To construct a function that runs `getpid` on a remote cluster, we wrap it using `rh.function`, and send it to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FI6SVrsBdHD8",
    "outputId": "e45084e8-6f1c-4dd4-9885-3ff55f3de53f"
   },
   "outputs": [],
   "source": [
    "# Remote Function\n",
    "getpid_remote = rh.function(fn=getpid).to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWHaw8bx0tQS"
   },
   "source": [
    "To run the function, simply call it just as you would a local function, and the function automatically runs on your specified hardware!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoFbUjcYdTCW",
    "outputId": "6da0aeef-36b0-4936-b700-633c09292be4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:33:21.308681 | Calling getpid.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local function result: 68830\n",
      "base_env servlet: Calling method call on module getpid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:33:21.668737 | Time to call getpid.call: 0.36 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote function result: 31069\n"
     ]
    }
   ],
   "source": [
    "print(f\"local function result: {getpid()}\")\n",
    "print(f\"remote function result: {getpid_remote()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suFeG-GGcjRz"
   },
   "source": [
    "#### `stream_logs`\n",
    "\n",
    "By default, logs and stdout will stream back to you as the function runs. If you're quite latency sensitive, you may see a slight performance gain if you disable it by passing `stream_logs=False` to the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vwVOSLMcd1n",
    "outputId": "e54ab648-bed6-4966-d632-f783d020fe7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31069"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getpid_remote(stream_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJL0TXCnKvWr"
   },
   "source": [
    "Function logs are also automatically output onto a log file on cluster it is run on. You can refer to [Runhouse Logging Docs](https://www.run.house/docs/debugging_logging) for more information on accessing these logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n",
    "\n",
    "A `Function` is actually a subclass of a more generic Runhouse concept called a `Module`, which represents the class analogue to a function. Like `Function`, you can send a `Module` to a remote cluster and interact with it natively by calling its methods, but it can also persist and utilize live state via instance methods. This is a superpower of Runhouse - often introducing state into a service means spinning up, connecting, and securing auxiliary services like Redis, Celery, etc. In Runhouse, state is built in, and lives natively in-memory in Python so it's ridiculously fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting existing class to Runhouse Module\n",
    "\n",
    "If you have an existing non-Runhouse class that you would like to run remotely, you can convert it into a `Module` via the `module` factory (not the lowercase m in `rh.module`):\n",
    "\n",
    "```\n",
    "from package import Model\n",
    "\n",
    "RemoteModel = rh.module(cls=Model, system=cluster)\n",
    "remote_model = RemoteModel(model_id=\"bert-base-uncased\", device=\"cuda\")\n",
    "remote_model.predict(\"Hello world!\")  # Runs on cluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own Runhouse Module\n",
    "\n",
    "You can also construct a new `Module` simply by subclassing `rh.Module` (note the uppercase M). Note that because you'll construct this class locally prior to sending it to a remote cluster, if there is a computationally heavy operation such as loading a dataset or model that you only want to be done remotely, you probably want to wrap that operation in an instance method and call it on the module after you've sent it to your remote compute. One way of doing so is through lazy initialization, as in the data property of the module below.\n",
    "\n",
    "When working in a notebook setting, we define the class in another file, `pid_module.py`, because module code is synced to the cluster and there isn't a robust standard for extracting code from notebooks. In normal Python, you can use any Module as you would a normal Python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pid_module.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pid_module.py\n",
    "\n",
    "import os\n",
    "import runhouse as rh\n",
    "\n",
    "class PIDModule(rh.Module):\n",
    "    def __init__(self, a: int=0):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        if not hasattr(self, '_data'):\n",
    "            self._data = load_dataset()\n",
    "        return self._data\n",
    "    \n",
    "    def getpid(self):\n",
    "        return os.getpid() + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pid_module import PIDModule\n",
    "\n",
    "remote_module = PIDModule(a=5).to(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:52:41.394668 | Calling PIDModule.getpid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_env servlet: Calling method getpid on module PIDModule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:52:41.633281 | Time to call PIDModule.getpid: 0.24 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31074"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_module.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D38sOsnPP5V_"
   },
   "source": [
    "## Env + Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9lns9sCZdt7"
   },
   "source": [
    "Our sample `getpid` function used only builtin Python dependencies, so we did not need to worry about the function environment.\n",
    "\n",
    "For more complex functions relying on external dependencies, Runhouse provides concepts for packages (individual dependencies/installations) and environments (group of packages or a conda env)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMOrsBjTP9lk"
   },
   "source": [
    "### Package Types\n",
    "\n",
    "Runhouse supports `pip`, `conda`, `reqs` and `git` packages, which can be constructed in the following ways.\n",
    "\n",
    "Often times, if using Packages in the context of environments (Envs), you don't need to construct them yourself, but can just pass in the corresponding string, and Runhouse internals will handle the conversion and installation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S7TtI1aS5JSj"
   },
   "outputs": [],
   "source": [
    "pip_package = rh.Package.from_string(\"pip:numpy\")\n",
    "conda_package = rh.Package.from_string(\"conda:torch\")\n",
    "reqs_package = rh.Package.from_string(\"reqs:./\")\n",
    "git_package = rh.GitPackage(git_url='https://github.com/huggingface/diffusers.git',\n",
    "                            install_method='pip',\n",
    "                            revision='v0.11.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6eVhkQu6H6C"
   },
   "source": [
    "You can also send packages between local, remote, and file storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRBA-30UWknH"
   },
   "outputs": [],
   "source": [
    "local_package = rh.Package.from_string(\"./\")  # ./ defaults to the current git root, but you can also pass an abs path\n",
    "\n",
    "# package_on_s3 = local_package.to(system=\"s3\", path=\"/s3/path/to/folder\")\n",
    "package_on_cluster = local_package.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z65ZySQdQCaz"
   },
   "source": [
    "### Envs\n",
    "\n",
    "Envs, or environments, keep track of your package installs and corresponding versions. This allows for reproducible dev environments, and convenient dependency isolation and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaFnxpbZPOd2"
   },
   "source": [
    "#### Base Env\n",
    "\n",
    "The basic Env resource just consists of a list of Packages, or strings that represent the packages. You can additionally add any environment variables by providing a Dict or `.env` local file path, and also set the working directory to be synced over (defaults to base GitHub repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fsCsZiOJ8GUZ"
   },
   "outputs": [],
   "source": [
    "env = rh.env(reqs=[\"numpy\", reqs_package, git_package], env_vars={\"USER\": \"*****\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYaXVF2VZEnJ"
   },
   "source": [
    "When you send an environment object to a cluster, the environment is automatically set up (packages are installed) on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Mk8HKgFZe9M"
   },
   "outputs": [],
   "source": [
    "env_on_cluster = env.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnZxyX9AQqw-"
   },
   "source": [
    "#### Conda Env\n",
    "\n",
    "The CondaEnv resource represents a Conda environment that can be used to set up reproducible Conda envs across clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2fwlQ0gRZhT"
   },
   "source": [
    "There are several ways to construct a Runhouse CondaEnv object using `rh.conda_env`, by passing in any of the following into the `conda_env` parameter:\n",
    "\n",
    "1. A yaml file corresponding to a conda environment config\n",
    "```\n",
    "conda_env = rh.conda_env(conda_env=\"conda_env.yml\", reqs=[\"numpy\", \"diffusers\"], name=\"yaml_env\")\n",
    "```\n",
    "2. A dict corresponding to a conda environment config\n",
    "```\n",
    "conda_dict = {\"name\": \"conda_env\", \"channels\": [\"conda-forge\"], \"dependencies\": [\"python=3.10.0\"]}\n",
    "conda_env = rh.env(conda_env=conda_dict, name=\"dict_env\")\n",
    "```\n",
    "3. Name of an existing conda env on your local machine\n",
    "```\n",
    "conda_env = rh.conda_env(conda_env=\"local_conda_env\", name=\"from_local_env\")\n",
    "```\n",
    "4. Leaving the argument empty. In this case, we'll construct a new Conda environment for you, using the list you pass into `reqs`.\n",
    "```\n",
    "conda_env = rh.conda_env(reqs=[\"numpy\", \"diffusers\"], name=\"new_env\")\n",
    "```\n",
    "\n",
    "Beyond the conda config, you can also add any additional requirements you'd like to install in the environment by adding `reqs = List[packages]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Lz2BZAH0QqXK"
   },
   "outputs": [],
   "source": [
    "conda_env = rh.conda_env(reqs=[\"numpy\", \"diffusers\"], name=\"new_env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqHqsaGNTy14"
   },
   "source": [
    "As with the base env, we can set up a conda env on the cluster with (note, this command might appear to hang, but it may be updating conda in the backgroud for a few minutes the first time you run it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBYx4X3oVMod"
   },
   "outputs": [],
   "source": [
    "conda_env_on_cluster = conda_env.to(system=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2F9cAkYVRGL"
   },
   "source": [
    "Previously in the cluster section, we mentioned several cluster APIs such as running CLI or Python commands. These all run on the base environment in the examples above, but now that we've defined a Conda env, let's demonstrate how we can accomplish this inside a Conda env on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BEIQXjJKXYyx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added '3.83.88.203' (ED25519) to the list of known hosts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.3\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '1.26.3\\n\\n\\n',\n",
       "  \"Warning: Permanently added '3.83.88.203' (ED25519) to the list of known hosts.\\r\\n\")]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run Python command within the conda env\n",
    "cluster.run_python(['import numpy', 'print(numpy.__version__)'], env=conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install additional package on given env\n",
    "cluster.install_packages([\"pandas\"], env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc1W9n1S8HPy"
   },
   "source": [
    "## Putting it all together -- Cluster, Function/Module, Env\n",
    "\n",
    "Now that we understand how clusters, functions, and packages/environments work, we can go on to implement more complex functions that require external dependencies, and seamlessly run them on a remote cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "M-msQEA0WmAv"
   },
   "outputs": [],
   "source": [
    "def add_lists(list_a, list_b):\n",
    "  import numpy as np\n",
    "\n",
    "  return np.add(np.array(list_a), np.array(list_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAYAUXusa7Hk"
   },
   "source": [
    "Note that in the function defined, we include the import statement `import numpy as np` within the function. The import needs to be inside the function definition in notebook or interactive environments, but can be outside the function if being used in a Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRHEbdJvbrR2"
   },
   "outputs": [],
   "source": [
    "env = rh.env(reqs=[\"numpy\"])\n",
    "add_lists_remote = rh.function(fn=add_lists).to(system=cluster, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:52:00.149572 | Calling add_lists.call\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_env servlet: Calling method call on module add_lists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-01-12 16:52:00.433690 | Time to call add_lists.call: 0.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_a = [1, 2, 3]\n",
    "list_b = [2, 3, 4]\n",
    "add_lists_remote(list_a, list_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agWXh0XoYnUw"
   },
   "source": [
    "Now that you understand the basics, feel free to play around with more complicated scenarios! You can also check out our additional API and example usage tutorials on our [docs site](https://www.run.house/docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Td4tq3e8NPS"
   },
   "source": [
    "## Cluster Termination\n",
    "\n",
    "To terminate the cluster, you can call `sky down cluster-name` in CLI or `cluster_obj.teardown()` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjrsEks-P7QE",
    "outputId": "8a1fdcd0-61d7-41db-a24f-cb86109497c4"
   },
   "outputs": [],
   "source": [
    "!sky down cpu-cluster\n",
    "# or\n",
    "cluster.teardown()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
